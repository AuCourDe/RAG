# ğŸµ ObsÅ‚uga plikÃ³w audio w systemie RAG

## âœ… **NOWA FUNKCJONALNOÅšÄ†!**

System RAG teraz obsÅ‚uguje pliki audio z:
- ğŸ¤ **TranskrypcjÄ…** (Whisper AI)
- ğŸ‘¥ **Rozpoznawaniem mÃ³wcÃ³w** (pyannote.audio)
- â±ï¸ **Timestampami** (Å‚atwe lokalizowanie fragmentÃ³w)

---

## ğŸ“ **ObsÅ‚ugiwane formaty audio:**

- âœ… **MP3** - najpopularniejszy
- âœ… **WAV** - bezstratny
- âœ… **FLAC** - bezstratny skompresowany
- âœ… **OGG** - open source
- âœ… **M4A** - Apple audio

---

## ğŸš€ **Jak uÅ¼ywaÄ‡:**

### **Krok 1: Dodaj plik audio**

**Przez interfejs:**
```
1. OtwÃ³rz http://localhost:8501
2. ZakÅ‚adka "Indeksowanie"
3. PrzeciÄ…gnij plik MP3/WAV/etc
4. Kliknij "Zapisz pliki"
```

**Przez folder:**
```bash
# Skopiuj plik do data/
cp nagranie.mp3 /home/rev/projects/RAG2/data/

# Watchdog automatycznie wykryje i przetworzy
```

### **Krok 2: Poczekaj na przetworzenie**

**Timeline (przykÅ‚ad: 5-minutowe nagranie MP3):**
```
t=0s      : Plik dodany
t=2s      : Watchdog wykrywa
t=3s      : Åadowanie modelu Whisper (~10-30s przy pierwszym uÅ¼yciu)
t=30s     : Model zaÅ‚adowany
t=35s     : Transkrypcja rozpoczÄ™ta
t=120s    : Transkrypcja zakoÅ„czona (5 min audio = ~90s przetwarzania)
t=125s    : Rozpoznawanie mÃ³wcÃ³w (opcjonalne, +30s)
t=160s    : Tworzenie fragmentÃ³w z timestampami
t=165s    : Embeddingi (GPU)
t=170s    : Zapis do bazy
t=200s    : Generowanie pytaÅ„
t=230s    : KONIEC - audio zaindeksowane!
```

**Dla 60-minutowego nagrania: ~10-15 minut przetwarzania**

---

## ğŸ“Š **Co siÄ™ dzieje po dodaniu audio:**

### **Transkrypcja (Whisper AI):**

**WejÅ›cie:** `rozmowa.mp3` (5 minut, 2 osoby)

**Whisper przetwarza:**
```
Model: Whisper base (szybki) lub medium/large (dokÅ‚adniejszy)
JÄ™zyk: Polski (automatyczne wykrycie)
GPU: RTX 3060 (jeÅ›li dostÄ™pna)
```

**Wynik - segmenty z timestampami:**
```
Segment 1: [00:00 - 00:05] "DzieÅ„ dobry, chciaÅ‚bym zapytaÄ‡ o..."
Segment 2: [00:05 - 00:12] "Tak, oczywiÅ›cie. W sprawie umowy..."
Segment 3: [00:12 - 00:20] "Rozumiem. A czy moÅ¼liwe jest..."
...
```

### **Rozpoznawanie mÃ³wcÃ³w (opcjonalne):**

**pyannote.audio analizuje:**
- Cechy gÅ‚osu
- Pauzy miÄ™dzy wypowiedziami
- Zmiany mÃ³wcÃ³w

**Wynik:**
```
Segment 1: [00:00 - 00:05] [SPEAKER_00] "DzieÅ„ dobry..."
Segment 2: [00:05 - 00:12] [SPEAKER_01] "Tak, oczywiÅ›cie..."
Segment 3: [00:12 - 00:20] [SPEAKER_00] "Rozumiem..."
```

### **Fragmenty w bazie:**

**PrzykÅ‚adowe fragmenty:**
```
Fragment 1:
ID: abc-123
TreÅ›Ä‡: "[00:00 - 00:05] [SPEAKER_00] DzieÅ„ dobry, chciaÅ‚bym 
        zapytaÄ‡ o szczegÃ³Å‚y umowy dotyczÄ…cej projektu."
Typ: audio_transcription
Source: rozmowa.mp3
Element: audio_segment_1_00m00s

Fragment 2:
ID: def-456
TreÅ›Ä‡: "[00:05 - 00:12] [SPEAKER_01] Tak, oczywiÅ›cie. W sprawie 
        umowy projekt jest zaplanowany na trzy etapy..."
Typ: audio_transcription
Source: rozmowa.mp3
Element: audio_segment_2_00m05s
```

---

## ğŸ” **Wyszukiwanie w audio:**

### **PrzykÅ‚ad 1: Pytanie o konkretny temat**

**Pytanie:**
```
"O czym rozmawiano w sprawie projektu?"
```

**System:**
1. Znajdzie fragmenty zawierajÄ…ce "projekt"
2. ZwrÃ³ci: 
   ```
   [00:05] SPEAKER_01: "W sprawie umowy projekt jest 
                        zaplanowany na trzy etapy..."
   [02:30] SPEAKER_00: "Projekt wymaga zatwierdzenia..."
   [04:15] SPEAKER_01: "Termin projektu to..."
   ```
3. Wygeneruje odpowiedÅº podsumowujÄ…cÄ…
4. **Bonus:** Wiesz KIEDY (timestamp) i KTO (speaker) to powiedziaÅ‚!

### **PrzykÅ‚ad 2: Szukanie wypowiedzi konkretnej osoby**

**Pytanie:**
```
"Co powiedziaÅ‚ SPEAKER_01?"
```

**System:**
- Znajdzie wszystkie fragmenty z [SPEAKER_01]
- Podsumuje wypowiedzi tej osoby

### **PrzykÅ‚ad 3: Lokalizacja w czasie**

**Pytanie:**
```
"Co byÅ‚o mÃ³wione okoÅ‚o 5 minuty nagrania?"
```

**System:**
- Znajdzie fragment: [05:00 - 05:15]
- ZwrÃ³ci transkrypcjÄ™ tego momentu

---

## ğŸ¯ **PrzykÅ‚adowe fragmenty:**

### **Audio z jednym mÃ³wcÄ… (podcast, wykÅ‚ad):**
```
Plik: wykÅ‚ad_matematyka.mp3 (60 minut)

Fragmenty:
[00:00 - 00:15] "Dzisiaj omÃ³wimy pojÄ™cie pochodnej funkcji..."
[00:15 - 00:35] "Pochodna jest zdefiniowana jako granica..."
[00:35 - 01:05] "PrzykÅ‚ad pierwszy. Mamy funkcjÄ™ f(x) = x^2..."
...

RAZEM: ~240 fragmentÃ³w (60 min Ã· 15s Å›redni segment)
```

### **Audio z rozmowÄ… (2+ mÃ³wcÃ³w):**
```
Plik: spotkanie_biznesowe.mp3 (30 minut, 3 osoby)

Fragmenty:
[00:00 - 00:08] [SPEAKER_00] "Zaczynamy spotkanie, pierwszy punkt..."
[00:08 - 00:22] [SPEAKER_01] "W sprawie budÅ¼etu mam pytanie..."
[00:22 - 00:40] [SPEAKER_02] "Zgadzam siÄ™ z propozycjÄ…..."
[00:40 - 00:55] [SPEAKER_00] "Dobrze, przechodzimy do..."
...

RAZEM: ~180 fragmentÃ³w (30 min Ã· 10s Å›redni segment)
```

---

## ğŸ’¡ **Zalety transkrypcji audio:**

### **1. Przeszukiwalne nagrania**
```
PRZED: 
"Mam gdzieÅ› w nagraniu info o umowie... (przesÅ‚uchaj 2h)"

PO:
Pytanie: "Co byÅ‚o mÃ³wione o umowie?"
â†’ Natychmiastowa odpowiedÅº z timestampem!
```

### **2. Timestampy = Å‚atwa lokalizacja**
```
OdpowiedÅº: "WedÅ‚ug fragmentu [1], o godzinie 00:15:30 
           SPEAKER_01 powiedziaÅ‚: 'Umowa zostanie podpisana...'"

â†’ Wiesz DOKÅADNIE gdzie w nagraniu szukaÄ‡!
```

### **3. Rozpoznawanie mÃ³wcÃ³w**
```
MoÅ¼esz pytaÄ‡:
- "Co powiedziaÅ‚ pierwszy mÃ³wca?"
- "Kto mÃ³wiÅ‚ o budÅ¼ecie?"
- "Ile czasu mÃ³wiÅ‚ SPEAKER_02?"
```

### **4. PeÅ‚na integracja z RAG**
```
W bazie razem:
- PDF z umowami
- Nagranie spotkania o umowach
- ZdjÄ™cia dokumentÃ³w

Pytanie: "Jakie sÄ… warunki umowy?"
â†’ OdpowiedÅº z PDF + transkrypcji!
```

---

## âš™ï¸ **Konfiguracja (opcjonalna):**

### **Zmiana modelu Whisper:**

Edytuj `rag_system.py`, linia ~469:
```python
# OBECNIE: base (szybki, mniej dokÅ‚adny)
model = whisper.load_model("base")

# OPCJE:
model = whisper.load_model("tiny")    # Najszybszy, najmniej dokÅ‚adny
model = whisper.load_model("base")    # Zbalansowany âœ… (domyÅ›lny)
model = whisper.load_model("small")   # Dobry kompromis
model = whisper.load_model("medium")  # DokÅ‚adny, wolniejszy
model = whisper.load_model("large")   # NajdokÅ‚adniejszy, najwolniejszy
```

**PorÃ³wnanie:**

| Model | Rozmiar | VRAM | Czas (5 min audio) | DokÅ‚adnoÅ›Ä‡ |
|-------|---------|------|-------------------|------------|
| **tiny** | 75 MB | 1 GB | ~30s | 80% |
| **base** | 145 MB | 1 GB | ~90s | 90% âœ… |
| **small** | 470 MB | 2 GB | ~180s | 94% |
| **medium** | 1.5 GB | 5 GB | ~360s | 96% |
| **large** | 3 GB | 10 GB | ~600s | 98% |

**Rekomendacja:** **base** (dobry kompromis szybkoÅ›Ä‡/jakoÅ›Ä‡)

---

## ğŸ”§ **Wymagane biblioteki:**

**Automatycznie w requirements.txt:**
```
openai-whisper>=20231117  # Transkrypcja
pyannote.audio>=3.1.0     # Rozpoznawanie mÃ³wcÃ³w
librosa>=0.10.0           # Audio processing
soundfile>=0.12.0         # Audio I/O
```

**Instalacja (jeÅ›li potrzebne):**
```bash
cd /home/rev/projects/RAG2
pip install openai-whisper pyannote.audio librosa soundfile
```

---

## ğŸ§ª **Test - Dodaj pierwsze audio:**

### **Krok po kroku:**

**1. Przygotuj plik MP3**
```
Nagranie testowe: 1-2 minuty
JÄ™zyk: polski
Format: MP3, WAV lub FLAC
```

**2. Dodaj do systemu**
```
Frontend â†’ Indeksowanie â†’ Upload â†’ test.mp3
â†’ Kliknij "Zapisz pliki"
```

**3. Obserwuj logi**
```bash
tail -f /home/rev/projects/RAG2/file_watcher.log

Zobaczysz:
"Rozpoczynanie przetwarzania pliku audio: test.mp3"
"Åadowanie modelu Whisper..."
"Model Whisper zaÅ‚adowany"
"Transkrypcja pliku audio... (moÅ¼e potrwaÄ‡ kilka minut)"
"Transkrypcja zakoÅ„czona w 95.23 sekund"
"Rozpoznano 45 segmentÃ³w audio"
"PrÃ³ba rozpoznawania mÃ³wcÃ³w..."
"Rozpoznano 2 mÃ³wcÃ³w"
"ZakoÅ„czono przetwarzanie audio, utworzono 45 fragmentÃ³w"
```

**4. SprawdÅº fragmenty**
```bash
cd /home/rev/projects/RAG2
python3 -c "
from rag_system import RAGSystem
rag = RAGSystem()
results = rag.vector_db.collection.get(
    where={'source_file': 'test.mp3'},
    limit=5
)
for doc in results['documents']:
    print(doc[:200])
    print('---')
"
```

**5. Zadaj pytanie**
```
Frontend â†’ Zapytania â†’ "O czym byÅ‚a mowa w nagraniu?"
```

**6. Zobacz odpowiedÅº z timestampami!**
```
WedÅ‚ug fragmentu [1], w czasie 00:15-00:30, SPEAKER_00 powiedziaÅ‚: 
"[cytat z transkrypcji]".

Fragment [2] (02:45-03:00) dodaje...

Å¹rÃ³dÅ‚a:
[1] test.mp3 - Segment 00:15
[2] test.mp3 - Segment 02:45
```

---

## ğŸ’¾ **Rozmiar modeli:**

**Whisper (pobierany automatycznie przy pierwszym uÅ¼yciu):**
```
models/whisper/
â”œâ”€â”€ tiny.pt     (75 MB)
â”œâ”€â”€ base.pt     (145 MB)  â† DomyÅ›lny
â”œâ”€â”€ small.pt    (470 MB)
â”œâ”€â”€ medium.pt   (1.5 GB)
â””â”€â”€ large-v3.pt (3 GB)
```

**pyannote (opcjonalnie):**
```
~/.cache/torch/hub/
â””â”€â”€ speaker-diarization-3.1/  (~500 MB)
```

**ÅÄ…czny rozmiar: ~650 MB - 4 GB** (zaleÅ¼y od modelu)

---

## âš¡ **WydajnoÅ›Ä‡:**

### **RTX 3060 12GB (TwÃ³j sprzÄ™t):**

| Audio | DÅ‚ugoÅ›Ä‡ | Model | Transkrypcja | Diarization | Razem |
|-------|---------|-------|--------------|-------------|-------|
| Podcast | 5 min | base | ~90s | -  | **~2 min** |
| Rozmowa | 5 min | base | ~90s | +30s | **~2.5 min** |
| WykÅ‚ad | 60 min | base | ~18 min | - | **~20 min** |
| Meeting | 60 min | base | ~18 min | +5 min | **~25 min** |

**SzybkoÅ›Ä‡:** ~1:3 (1 minuta audio = 3 minuty przetwarzania)

### **CPU (bez GPU):**
```
~2-3Ã— wolniej
5 min audio = ~6-9 minut przetwarzania
```

---

## ğŸ¤ **PrzykÅ‚ady uÅ¼ycia:**

### **Use Case 1: Transkrypcja spotkaÅ„**
```
Plik: spotkanie_zespolu.mp3 (30 min, 5 osÃ³b)

Po zaindeksowaniu:
- 180 fragmentÃ³w transkrypcji
- 5 mÃ³wcÃ³w rozpoznanych
- KaÅ¼dy fragment z timestampem

Pytania:
"Kto mÃ³wiÅ‚ o deadline?"
"Co byÅ‚o ustalone w sprawie budÅ¼etu?"
"Ile czasu trwaÅ‚a dyskusja o projekcie?"
```

### **Use Case 2: WykÅ‚ady/prezentacje**
```
Plik: wyklad_ai.mp3 (90 min, 1 osoba)

Po zaindeksowaniu:
- 360 fragmentÃ³w
- Timestampy co ~15 sekund

Pytania:
"Jak zdefiniowano AI?"
"Kiedy byÅ‚y omawiane sieci neuronowe?" â†’ odpowiedÅº z timestampem!
"Podsumuj gÅ‚Ã³wne punkty wykÅ‚adu"
```

### **Use Case 3: Wywiady**
```
Plik: wywiad_specjalista.mp3 (45 min, 2 osoby)

Po zaindeksowaniu:
- 270 fragmentÃ³w
- 2 mÃ³wcÃ³w (interviewer + ekspert)

Pytania:
"Co powiedziaÅ‚ ekspert o regulacjach?"
"Jakie byÅ‚y pytania zadane przez prowadzÄ…cego?"
```

### **Use Case 4: Mieszane ÅºrÃ³dÅ‚a**
```
W bazie razem:
- PDF: "Umowa_2024.pdf"
- Audio: "Negocjacje_umowy.mp3"
- Word: "Notatki_ze_spotkania.docx"

Pytanie: "Jakie sÄ… warunki pÅ‚atnoÅ›ci?"

OdpowiedÅº bÄ™dzie z WSZYSTKICH ÅºrÃ³deÅ‚:
- PDF: artykuÅ‚y umowy
- Audio: co byÅ‚o mÃ³wione o pÅ‚atnoÅ›ciach
- Word: notatki po spotkaniu

PEÅNY OBRAZ! ğŸ¯
```

---

## ğŸ¨ **Format fragmentÃ³w w bazie:**

**Struktura:**
```
[MM:SS - MM:SS] [SPEAKER_XX] Transkrypcja tekstu

PrzykÅ‚ad:
[02:15 - 02:30] [SPEAKER_01] W sprawie budÅ¼etu proponujÄ™ 
zwiÄ™kszenie o dziesiÄ™Ä‡ procent, poniewaÅ¼ koszty wzrosÅ‚y.
```

**Metadane:**
```json
{
  "source_file": "spotkanie.mp3",
  "page_number": 0,
  "chunk_type": "audio_transcription",
  "element_id": "audio_segment_15_02m15s"
}
```

---

## âš ï¸ **WaÅ¼ne uwagi:**

### **1. Pierwsze uruchomienie = dÅ‚uÅ¼sze**
```
Przy pierwszym pliku audio:
- Pobieranie modelu Whisper: ~1-3 minuty
- Pobieranie pyannote (jeÅ›li dostÄ™pny): ~2-5 minut

Kolejne pliki: juÅ¼ szybko (model w cache)
```

### **2. VRAM dla duÅ¼ych modeli**
```
RTX 3060 12GB:
âœ… Whisper base: 1 GB VRAM âœ…
âœ… Whisper medium: 5 GB VRAM âœ…
âš ï¸ Whisper large: 10 GB VRAM (ciasno z innymi modelami)

JeÅ›li model embeddingowy juÅ¼ zaÅ‚adowany (5 GB):
- Base: OK (1+5 = 6 GB)
- Medium: OK (5+5 = 10 GB, ciasno)
- Large: âŒ Overflow (10+5 = 15 GB > 12 GB)

RozwiÄ…zanie: Ollama rozÅ‚aduje modele automatycznie
```

### **3. JÄ™zyki**
```
Whisper wspiera 99 jÄ™zykÃ³w!
- Polski âœ… (domyÅ›lny w kodzie)
- Angielski âœ…
- Inne: zmieÅ„ "pl" â†’ "en", "de", etc.
```

### **4. JakoÅ›Ä‡ nagrania**
```
âœ… Dobre: czysta mowa, maÅ‚o szumu
âš ï¸ Åšrednie: szum w tle, echo
âŒ ZÅ‚e: bardzo gÅ‚oÅ›ny szum, znieksztaÅ‚cenia

Whisper radzi sobie z szumem, ale jakoÅ›Ä‡ wpÅ‚ywa na dokÅ‚adnoÅ›Ä‡.
```

---

## ğŸ”’ **BezpieczeÅ„stwo:**

### **PrywatnoÅ›Ä‡:**
```
âœ… Wszystko lokalne (nie wysyÅ‚a na zewnÄ…trz)
âœ… Whisper na GPU (offline)
âœ… Dane nie opuszczajÄ… komputera
âœ… Temp files automatycznie usuwane
```

### **WraÅ¼liwe nagrania:**
```
System RAG idealny dla:
âœ… Nagrania medyczne (prywatnoÅ›Ä‡!)
âœ… Nagrania prawne (poufnoÅ›Ä‡)
âœ… Spotkania biznesowe (NDA)
âœ… Wywiady (zgoda osoby)

BO: wszystko lokalne, zero cloud!
```

---

## ğŸ“š **Dokumentacja techniczna:**

### **Kod:**
- `rag_system.py`, linia 453-564: `_process_audio()`
- Bazuje na projekcie `/home/rev/projects/Whisper/`
- Integracja: Whisper + pyannote + RAG

### **Model Whisper:**
- OpenAI Whisper (open source)
- https://github.com/openai/whisper
- Licencja: MIT

### **pyannote.audio:**
- Speaker diarization
- https://github.com/pyannote/pyannote-audio
- Wymaga: akceptacja licencji na HuggingFace

---

## ğŸŠ **Gotowe!**

**System RAG teraz obsÅ‚uguje:**
- âœ… PDF (tekst + obrazy)
- âœ… DOCX (tekst + obrazy)
- âœ… XLSX (tekst + obrazy + wykresy)
- âœ… JPG/PNG (rozpoznawanie przez AI)
- âœ… **MP3/WAV/FLAC/OGG (transkrypcja + mÃ³wcy)** ğŸ†•

**Multimodalny AI w peÅ‚nej okazaÅ‚oÅ›ci!** ğŸš€ğŸµğŸ“„ğŸ–¼ï¸


