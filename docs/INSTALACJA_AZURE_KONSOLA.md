# ğŸš€ INSTALACJA RAG NA AZURE VM - KONSOLA SZEREGOWA

## Instrukcja krok po kroku dla Azure Virtual Machine

**DostÄ™p:** Tylko konsola szeregowa (Serial Console)  
**System:** Ubuntu 20.04+ lub 22.04 LTS  
**Czas instalacji:** ~30-45 minut (zaleÅ¼nie od prÄ™dkoÅ›ci sieci)

---

## ğŸ“‹ WYMAGANIA WSTÄ˜PNE

### 1. Azure VM - minimalna konfiguracja:
- **CPU:** 4 vCPU (zalecane: 8 vCPU)
- **RAM:** 16 GB (zalecane: 32 GB)
- **Dysk:** 100 GB SSD
- **GPU:** Opcjonalnie NVIDIA (dla lepszej wydajnoÅ›ci)
- **OS:** Ubuntu 22.04 LTS
- **Porty:** 8501 (Streamlit), 11434 (Ollama)

### 2. DostÄ™p do konsoli szeregowej:
- Azure Portal â†’ Virtual Machines â†’ Twoja VM â†’ Serial Console
- Login: uÅ¼ytkownik z sudo

---

## ğŸ”§ INSTALACJA - KROK PO KROKU

### KROK 1: Aktualizacja systemu i instalacja podstawowych narzÄ™dzi

```bash
# Zaloguj siÄ™ do konsoli szeregowej
# Login: <twoj_user>
# Password: <twoje_haslo>

# SprawdÅº system
uname -a
cat /etc/os-release

# Aktualizacja
sudo apt update
sudo apt upgrade -y

# Instalacja podstawowych narzÄ™dzi
sudo apt install -y \
    git \
    python3 \
    python3-venv \
    python3-pip \
    ffmpeg \
    tesseract-ocr \
    tesseract-ocr-pol \
    curl \
    wget \
    htop \
    nano \
    build-essential

# SprawdÅº wersje
python3 --version  # Powinno byÄ‡ 3.10+
git --version
ffmpeg -version
```

**Oczekiwany czas:** 5-10 minut

---

### KROK 2: Instalacja Ollama (LLM backend)

```bash
# Pobierz i zainstaluj Ollama
curl -fsSL https://ollama.com/install.sh | sh

# SprawdÅº instalacjÄ™
systemctl status ollama

# JeÅ›li nie dziaÅ‚a, uruchom:
sudo systemctl start ollama
sudo systemctl enable ollama

# Pobierz model gemma3:12b (~7 GB, moÅ¼e potrwaÄ‡ 10-20 minut)
ollama pull gemma3:12b

# SprawdÅº czy dziaÅ‚a
ollama list
curl http://localhost:11434/api/tags

# PowinieneÅ› zobaczyÄ‡ gemma3:12b na liÅ›cie
```

**Oczekiwany czas:** 15-25 minut (pobieranie modelu)

---

### KROK 3: Clone repozytorium RAG

```bash
# PrzejdÅº do home directory
cd ~

# Clone projektu (publiczne repo)
git clone https://github.com/AuCourDe/RAG.git

# WejdÅº do folderu
cd RAG

# SprawdÅº strukturÄ™
ls -la

# PowinieneÅ› zobaczyÄ‡:
# app/, docs/, test/, start_all.sh, requirements.txt
```

**Oczekiwany czas:** 1-2 minuty

---

### KROK 4: Utworzenie Python Virtual Environment

```bash
# W folderze RAG
cd ~/RAG

# StwÃ³rz venv
python3 -m venv venv_rag

# Aktywuj venv
source venv_rag/bin/activate

# SprawdÅº czy aktywny (zobaczysz (venv_rag) przed promptem)
which python3
# Powinno pokazaÄ‡: ~/RAG/venv_rag/bin/python3
```

**Oczekiwany czas:** 1 minuta

---

### KROK 5: Instalacja zaleÅ¼noÅ›ci Python

```bash
# Upewnij siÄ™ Å¼e venv jest aktywny
source venv_rag/bin/activate

# Upgrade pip
pip install --upgrade pip setuptools wheel

# Instalacja zaleÅ¼noÅ›ci (~5-15 minut, wiele pakietÃ³w)
pip install -r requirements.txt

# To zainstaluje:
# - streamlit (UI)
# - chromadb (vector database)
# - sentence-transformers (embeddings)
# - openai-whisper (audio transcription)
# - opencv-python (video processing)
# - librosa (audio analysis)
# - scikit-learn (clustering)
# - ~50+ innych bibliotek

# UWAGA: MoÅ¼liwe ostrzeÅ¼enia o dependency conflicts - to normalne
```

**Oczekiwany czas:** 10-20 minut (zaleÅ¼nie od prÄ™dkoÅ›ci sieci)

**MoÅ¼liwe problemy:**
- **Error: "Could not build wheels for..."** â†’ Instaluj `build-essential`: `sudo apt install build-essential`
- **Slow download** â†’ To normalne, pakietÃ³w jest duÅ¼o

---

### KROK 6: Utworzenie potrzebnych folderÃ³w

```bash
# W folderze RAG
cd ~/RAG

# UtwÃ³rz foldery
mkdir -p data logs temp vector_db models

# SprawdÅº strukturÄ™
ls -la

# PowinieneÅ› zobaczyÄ‡ wszystkie foldery
```

**Oczekiwany czas:** < 1 minuta

---

### KROK 7: Konfiguracja firewall (NSG na Azure)

**W Azure Portal (nie w konsoli):**

1. PrzejdÅº do: Virtual Machines â†’ Twoja VM â†’ Networking
2. Kliknij: "Add inbound port rule"
3. Dodaj reguÅ‚Ä™:
   - **Destination port ranges:** 8501
   - **Protocol:** TCP
   - **Priority:** 1000
   - **Name:** AllowStreamlit
   - **Action:** Allow
4. Kliknij: "Add"

**Opcjonalnie - dla Ollama (jeÅ›li chcesz zdalny dostÄ™p):**
- **Port:** 11434
- **Name:** AllowOllama

**Dla konsoli SSH (jeÅ›li jeszcze nie ma):**
- **Port:** 22
- **Name:** AllowSSH

---

### KROK 8: (Opcjonalnie) GPU - instalacja CUDA

**TYLKO jeÅ›li masz VM z GPU (NC-series, NV-series)**

```bash
# SprawdÅº czy masz GPU
lspci | grep -i nvidia

# JeÅ›li TAK, zainstaluj CUDA
wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/cuda-keyring_1.1-1_all.deb
sudo dpkg -i cuda-keyring_1.1-1_all.deb
sudo apt update
sudo apt install -y cuda-toolkit-12-2 nvidia-driver-535

# Restart wymagany
sudo reboot

# Po restarcie sprawdÅº
nvidia-smi

# PowinieneÅ› zobaczyÄ‡ kartÄ™ GPU
```

**Oczekiwany czas:** 20-30 minut + restart

**JEÅšLI NIE MASZ GPU:** PomiÅ„ ten krok, aplikacja bÄ™dzie dziaÅ‚aÄ‡ na CPU.

---

### KROK 9: Test instalacji

```bash
# W folderze RAG
cd ~/RAG
source venv_rag/bin/activate

# Test importÃ³w
python3 -c "import streamlit; import chromadb; import torch; print('âœ… Importy OK')"

# Test Ollama
curl http://localhost:11434/api/tags

# SprawdÅº modele
ollama list
# Powinien byÄ‡: gemma3:12b
```

**Oczekiwany czas:** < 1 minuta

---

### KROK 10: Uruchomienie aplikacji

#### Opcja A: Przez start_all.sh (zalecane)

```bash
cd ~/RAG
source venv_rag/bin/activate
bash start_all.sh
```

**Co siÄ™ uruchomi:**
- File Watcher (tÅ‚o) - automatyczna indeksacja plikÃ³w
- Streamlit Frontend - UI na porcie 8501

**Zobaczysz:**
```
ğŸš€ Uruchamianie peÅ‚nego systemu RAG
====================================
ğŸ“ Katalog projektu: /home/<user>/RAG

ğŸ‘ï¸  Uruchamianie File Watcher (tÅ‚o)...
   âœ… Watchdog uruchomiony (PID: XXXX)

ğŸŒ Uruchamianie Frontend...
======================================

ğŸ“± DostÄ™p lokalny: http://localhost:8501
ğŸŒ DostÄ™p sieÄ‡ lokalna: http://<IP>:8501

ğŸ‘¤ Logowanie: admin / admin123

ğŸ’¡ Watchdog dziaÅ‚a w tle
â¹ï¸  NaciÅ›nij Ctrl+C aby zatrzymaÄ‡
```

#### Opcja B: Uruchomienie w tle (daemon)

```bash
cd ~/RAG
source venv_rag/bin/activate

# Uruchom w tle
nohup bash start_all.sh > logs/start_all.log 2>&1 &

# SprawdÅº logi
tail -f logs/start_all.log

# Zatrzymanie
pkill -f streamlit
pkill -f file_watcher
```

**Oczekiwany czas:** 1-2 minuty (pierwsze uruchomienie - pobieranie modeli)

---

### KROK 11: DostÄ™p do aplikacji

#### A. Z konsoli szeregowej (lokalnie):

```bash
# Nie moÅ¼esz otworzyÄ‡ przeglÄ…darki w konsoli szeregowej
# UÅ¼yj tunelu SSH lub publiczny IP
```

#### B. Przez publiczny IP Azure:

1. ZnajdÅº publiczny IP:
   ```bash
   curl ifconfig.me
   # Lub w Azure Portal: Overview â†’ Public IP address
   ```

2. OtwÃ³rz w przeglÄ…darce:
   ```
   http://<PUBLICZNY_IP>:8501
   ```

3. Login:
   - Username: `admin`
   - Password: `admin123`

#### C. Przez SSH Tunnel (bezpieczniejsze):

**Na twoim lokalnym komputerze:**

```bash
# UtwÃ³rz tunel SSH
ssh -L 8501:localhost:8501 <user>@<PUBLICZNY_IP_VM>

# Teraz otwÃ³rz w przeglÄ…darce lokalnie:
http://localhost:8501
```

---

### KROK 12: Weryfikacja dziaÅ‚ania

**W przeglÄ…darce (http://<IP>:8501):**

1. âœ… **Login:** admin / admin123
2. âœ… **Upload test file:** Dodaj PDF lub obraz
3. âœ… **SprawdÅº indeksacjÄ™:** Plik powinien byÄ‡ przetworzony
4. âœ… **Zadaj pytanie:** Wpisz pytanie i kliknij "Szukaj odpowiedzi"
5. âœ… **SprawdÅº monitoring:** GPU/CPU/RAM powinny siÄ™ odÅ›wieÅ¼aÄ‡

**W konsoli szeregowej:**

```bash
# SprawdÅº procesy
ps aux | grep streamlit
ps aux | grep file_watcher

# SprawdÅº logi
tail -f logs/rag_system.log
tail -f logs/streamlit.log

# SprawdÅº Ollama
ollama ps
```

---

### KROK 13: (Opcjonalnie) Automatyczne uruchomienie przy starcie VM

#### UtwÃ³rz systemd service:

```bash
# UtwÃ³rz plik service
sudo nano /etc/systemd/system/rag-system.service
```

**Wklej:**
```ini
[Unit]
Description=RAG System - Streamlit + File Watcher
After=network.target ollama.service
Wants=ollama.service

[Service]
Type=simple
User=<TWOJ_USER>
WorkingDirectory=/home/<TWOJ_USER>/RAG
Environment="PATH=/home/<TWOJ_USER>/RAG/venv_rag/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"
ExecStart=/home/<TWOJ_USER>/RAG/venv_rag/bin/python3 -m streamlit run app/app.py --server.address 0.0.0.0 --server.port 8501 --server.headless true
Restart=always
RestartSec=10

[Install]
WantedBy=multi-user.target
```

**Zapisz:** Ctrl+X, Y, Enter

```bash
# PrzeÅ‚aduj systemd
sudo systemctl daemon-reload

# WÅ‚Ä…cz autostart
sudo systemctl enable rag-system

# Uruchom
sudo systemctl start rag-system

# SprawdÅº status
sudo systemctl status rag-system

# Logi
journalctl -u rag-system -f
```

---

## ğŸ”’ BEZPIECZEÅƒSTWO

### 1. ZmieÅ„ domyÅ›lne hasÅ‚o

```bash
cd ~/RAG
source venv_rag/bin/activate
python3 app/manage_users.py
```

Wybierz: ZmieÅ„ hasÅ‚o dla `admin`

### 2. Firewall VM (opcjonalnie)

```bash
# WÅ‚Ä…cz UFW
sudo ufw enable

# PozwÃ³l SSH
sudo ufw allow 22/tcp

# PozwÃ³l Streamlit
sudo ufw allow 8501/tcp

# SprawdÅº status
sudo ufw status
```

### 3. SSL/HTTPS (opcjonalnie, dla produkcji)

```bash
cd ~/RAG
sudo bash setup_nginx_ssl.sh
```

**To zainstaluje:**
- Nginx (reverse proxy)
- Certbot (SSL certificates)
- Auto-redirect HTTP â†’ HTTPS

---

## ğŸ“Š MONITORING I DIAGNOSTYKA

### SprawdÅº czy wszystko dziaÅ‚a:

```bash
# 1. Ollama
systemctl status ollama
ollama list
curl http://localhost:11434/api/tags

# 2. Streamlit
ps aux | grep streamlit
netstat -tulpn | grep 8501

# 3. File Watcher
ps aux | grep file_watcher

# 4. Logi
tail -f ~/RAG/logs/rag_system.log
tail -f ~/RAG/logs/streamlit.log

# 5. GPU (jeÅ›li masz)
nvidia-smi

# 6. RAM/CPU
htop
```

### Logi w czasie rzeczywistym:

```bash
# Terminal 1: RAG system log
tail -f ~/RAG/logs/rag_system.log

# Terminal 2: Streamlit log
tail -f ~/RAG/logs/streamlit.log

# Terminal 3: File watcher log
tail -f ~/RAG/logs/file_watcher.log
```

---

## ğŸ› TROUBLESHOOTING

### Problem: "Port 8501 already in use"

```bash
# Zabij proces na porcie 8501
sudo lsof -ti:8501 | xargs kill -9

# Lub
pkill -f streamlit
```

### Problem: "Ollama connection refused"

```bash
# SprawdÅº czy dziaÅ‚a
systemctl status ollama

# Uruchom
sudo systemctl start ollama

# Test
curl http://localhost:11434/api/tags
```

### Problem: "No module named 'streamlit'"

```bash
# SprawdÅº czy venv jest aktywny
which python3
# Powinno byÄ‡: ~/RAG/venv_rag/bin/python3

# JeÅ›li nie, aktywuj:
source ~/RAG/venv_rag/bin/activate
```

### Problem: "CUDA not available" (jeÅ›li masz GPU)

```bash
# SprawdÅº drivers
nvidia-smi

# JeÅ›li brak, zainstaluj:
sudo apt install -y nvidia-driver-535
sudo reboot
```

### Problem: "Cannot access http://<IP>:8501"

```bash
# 1. SprawdÅº czy Streamlit dziaÅ‚a
ps aux | grep streamlit

# 2. SprawdÅº firewall Azure (NSG)
# Azure Portal â†’ VM â†’ Networking â†’ SprawdÅº port 8501

# 3. SprawdÅº local firewall
sudo ufw status
sudo ufw allow 8501/tcp

# 4. SprawdÅº czy sÅ‚ucha na 0.0.0.0
netstat -tulpn | grep 8501
# Powinno byÄ‡: 0.0.0.0:8501 (nie 127.0.0.1)
```

---

## ğŸ“ NOTATKI I WSKAZÃ“WKI

### 1. Konsola szeregowa - ograniczenia:
- âŒ Brak copy-paste (w niektÃ³rych przypadkach)
- âŒ Brak przeglÄ…darki
- âœ… PeÅ‚ny dostÄ™p do systemu
- âœ… DziaÅ‚a nawet gdy SSH nie dziaÅ‚a

**ObejÅ›cie:** UÅ¼yj SSH gdy juÅ¼ skonfigurujesz VM

### 2. Pierwsze uruchomienie - wolne:
- Pobieranie modeli Whisper (~3 GB)
- Pobieranie modeli Embeddings (~2 GB)
- Kompilacja niektÃ³rych bibliotek
- **Kolejne uruchomienia:** Szybkie (modele w cache)

### 3. Monitoring zasobÃ³w:

```bash
# RAM usage
free -h

# Disk usage
df -h

# GPU (jeÅ›li masz)
watch -n 1 nvidia-smi

# Procesy Python
ps aux | grep python3
```

### 4. Zatrzymanie aplikacji:

```bash
# Ctrl+C w terminalu gdzie dziaÅ‚a start_all.sh

# Lub kill processes:
pkill -f streamlit
pkill -f file_watcher

# SprawdÅº czy zatrzymane
ps aux | grep streamlit
```

---

## ğŸ”„ AKTUALIZACJA DO NOWSZEJ WERSJI

```bash
cd ~/RAG

# Zatrzymaj aplikacjÄ™
pkill -f streamlit
pkill -f file_watcher

# Pull latest
git pull origin main

# SprawdÅº nowe tagi
git tag -l

# Checkout konkretnej wersji (opcjonalnie)
git checkout v7

# Aktywuj venv i update dependencies
source venv_rag/bin/activate
pip install -r requirements.txt --upgrade

# Uruchom ponownie
bash start_all.sh
```

---

## ğŸ“Š TESTOWANIE PO INSTALACJI

### Quick test:

```bash
cd ~/RAG
source venv_rag/bin/activate

# Test basic
python3 -c "
from app.rag_system import RAGSystem
rag = RAGSystem()
print('âœ… RAG System dziaÅ‚a!')
"

# Test Ollama integration
python3 -c "
from app.model_provider import ModelFactory
provider = ModelFactory.create_provider()
print(f'âœ… Model provider: {provider}')
"
```

### W przeglÄ…darce:
1. Upload test PDF
2. Zadaj pytanie: "Co zawiera dokument?"
3. SprawdÅº czy odpowiedÅº siÄ™ generuje

---

## ğŸ¯ CHECKLIST KOÅƒCOWY

Po instalacji sprawdÅº:

- [ ] Ollama dziaÅ‚a (`systemctl status ollama`)
- [ ] Model gemma3:12b pobrany (`ollama list`)
- [ ] Python venv dziaÅ‚a (`source venv_rag/bin/activate`)
- [ ] Wszystkie dependencies zainstalowane (`pip list`)
- [ ] Foldery utworzone (`ls -la ~/RAG`)
- [ ] Port 8501 otwarty w NSG (Azure Portal)
- [ ] Streamlit odpowiada (`curl http://localhost:8501`)
- [ ] MoÅ¼esz zalogowaÄ‡ siÄ™ w przeglÄ…darce
- [ ] Upload pliku dziaÅ‚a
- [ ] Generowanie odpowiedzi dziaÅ‚a

**JeÅ›li wszystko âœ… â†’ Instalacja kompletna!** ğŸ‰

---

## ğŸ“ WSPARCIE

### Logi do diagnostyki:

```bash
# System RAG
~/RAG/logs/rag_system.log

# Streamlit
~/RAG/logs/streamlit.log

# File Watcher
~/RAG/logs/file_watcher.log

# Ollama
journalctl -u ollama -n 100

# System
journalctl -xe
```

### Restart wszystkiego:

```bash
# Zatrzymaj
pkill -f streamlit
pkill -f file_watcher

# Restart Ollama
sudo systemctl restart ollama

# Uruchom ponownie
cd ~/RAG
source venv_rag/bin/activate
bash start_all.sh
```

---

## ğŸš€ GOTOWE!

Po wykonaniu wszystkich krokÃ³w:

âœ… RAG System dziaÅ‚a  
âœ… DostÄ™pny przez przeglÄ…darkÄ™: `http://<IP>:8501`  
âœ… Ollama backend aktywny  
âœ… File watcher monitoruje folder `data/`  
âœ… Wszystko logowane do `logs/`  

**Aplikacja gotowa do uÅ¼ycia!** ğŸ‰

---

**Czas instalacji total:** ~40-60 minut  
**Autor instrukcji:** 2025-11-06  
**Wersja:** v7

